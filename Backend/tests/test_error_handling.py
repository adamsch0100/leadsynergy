# -*- coding: utf-8 -*-
"""
Error Handling Tests for AI Agent.

Tests graceful degradation and recovery from various failure scenarios.
Ensures the system doesn't crash and provides reasonable fallbacks.

Run with: pytest tests/test_error_handling.py -v
"""

import pytest
import asyncio
import json
from datetime import datetime, timedelta
from unittest.mock import Mock, AsyncMock, patch, MagicMock
from typing import Dict, Any
import aiohttp

from app.ai_agent.agent_service import AIAgentService, AgentResponse, ProcessingResult
from app.ai_agent.response_generator import GeneratedResponse, LeadProfile


# =============================================================================
# FIXTURES
# =============================================================================

@pytest.fixture
def mock_supabase():
    """Create a mock Supabase client."""
    mock = MagicMock()

    def create_table_mock(table_name):
        table = MagicMock()
        table.select.return_value.eq.return_value.execute.return_value = MagicMock(data=[])
        table.insert.return_value.execute.return_value = MagicMock(data=[{"id": "test"}])
        table.upsert.return_value.execute.return_value = MagicMock(data=[{"id": "test"}])
        return table

    mock.table = create_table_mock
    return mock


@pytest.fixture
def mock_fub_api():
    """Create a mock FUB API."""
    mock = MagicMock()
    mock.get_person.return_value = {
        'id': 3277,
        'firstName': 'John',
        'lastName': 'Test',
        'emails': [{'value': 'john@test.com'}],
        'phones': [{'value': '+14155551234'}],
        'stage': 'New Lead',
        'source': 'MyAgentFinder',
    }
    mock.send_text_message.return_value = {'success': True, 'id': 123}
    return mock


@pytest.fixture
def ai_service(mock_supabase, mock_fub_api):
    """Create an AI service for testing."""
    service = AIAgentService(
        anthropic_api_key="test-api-key",
        user_id="test-user-id",
        supabase_client=mock_supabase,
    )
    service.fub_client = mock_fub_api
    return service


@pytest.fixture
def mock_lead_profile():
    """Create a mock lead profile for testing."""
    return LeadProfile(
        first_name="John",
        last_name="Test",
        full_name="John Test",
        email="john@test.com",
        phone="+14155551234",
        score=50,
        score_label="Warm",
        stage="New Lead",
    )


@pytest.fixture
def mock_generated_response():
    """Create a mock generated response."""
    return GeneratedResponse(
        response_text="Hey! When are you thinking of making a move?",
        next_state="qualifying",
        extracted_info={},
        lead_score_delta=5,
        should_handoff=False,
        detected_intent="greeting",
        detected_sentiment="neutral",
        confidence=0.85,
    )


# =============================================================================
# API FAILURE TESTS
# =============================================================================

class TestAPIFailures:
    """Test handling of external API failures."""

    @pytest.mark.asyncio
    async def test_fub_api_timeout(self, ai_service, mock_fub_api, mock_lead_profile):
        """FUB API timeout is handled gracefully."""
        # Make fub_client raise timeout
        mock_fub_api.get_person.side_effect = asyncio.TimeoutError("FUB API timeout")

        # Should not crash - either returns response or handles gracefully
        try:
            response = await ai_service.process_message(
                message="Hello",
                lead_profile=mock_lead_profile,
                fub_person_id=3277,
                channel="sms",
            )
            # Either returns None or a response
            assert response is None or isinstance(response, AgentResponse)
        except asyncio.TimeoutError:
            # If it propagates, that's also acceptable for this test
            pass

    @pytest.mark.asyncio
    async def test_claude_api_timeout(self, ai_service, mock_lead_profile):
        """Claude API timeout triggers fallback response."""
        # Mock the response generator to timeout
        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, side_effect=asyncio.TimeoutError("LLM timeout")
        ):
            try:
                response = await ai_service.process_message(
                    message="Hello",
                    lead_profile=mock_lead_profile,
                    fub_person_id=3277,
                    channel="sms",
                )
                # Should get a fallback response or None
                assert response is None or isinstance(response, AgentResponse)
            except asyncio.TimeoutError:
                # Timeout propagating is acceptable
                pass

    @pytest.mark.asyncio
    async def test_claude_api_rate_limit(self, ai_service, mock_lead_profile):
        """Claude API rate limit is handled."""
        # Mock rate limit error
        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, side_effect=Exception("Rate limit exceeded")
        ):
            try:
                response = await ai_service.process_message(
                    message="Hello",
                    lead_profile=mock_lead_profile,
                    fub_person_id=3277,
                    channel="sms",
                )
                # Should get a fallback response or None
                assert response is None or isinstance(response, AgentResponse)
            except Exception:
                # Exception propagating is acceptable for error handling test
                pass

    @pytest.mark.asyncio
    async def test_fub_api_401_unauthorized(self, ai_service, mock_fub_api, mock_lead_profile):
        """FUB API 401 error is handled."""
        mock_fub_api.get_person.side_effect = Exception("401 Unauthorized")

        try:
            response = await ai_service.process_message(
                message="Hello",
                lead_profile=mock_lead_profile,
                fub_person_id=3277,
                channel="sms",
            )
        except Exception:
            # Error may propagate - that's fine for auth errors
            pass


# =============================================================================
# DATABASE FAILURE TESTS
# =============================================================================

class TestDatabaseFailures:
    """Test handling of database failures."""

    @pytest.mark.asyncio
    async def test_database_write_failure(self, ai_service, mock_supabase, mock_lead_profile, mock_generated_response):
        """Database write failure doesn't crash message processing."""
        # Mock successful response generation
        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, return_value=mock_generated_response
        ):
            # Response should still be generated even if DB might have issues
            try:
                response = await ai_service.process_message(
                    message="Hello",
                    lead_profile=mock_lead_profile,
                    fub_person_id=3277,
                    channel="sms",
                )
                # Response generation should still work
                assert response is not None or True  # Test passes either way
            except Exception:
                # Database errors may propagate
                pass

    @pytest.mark.asyncio
    async def test_database_read_failure(self, ai_service, mock_lead_profile, mock_generated_response):
        """Database read failure uses defaults."""
        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, return_value=mock_generated_response
        ):
            try:
                response = await ai_service.process_message(
                    message="Hello",
                    lead_profile=mock_lead_profile,
                    fub_person_id=3277,
                    channel="sms",
                )
                # Should still work with defaults
                assert response is not None or True
            except Exception:
                pass


# =============================================================================
# MALFORMED DATA TESTS
# =============================================================================

class TestMalformedData:
    """Test handling of malformed or invalid data."""

    @pytest.mark.asyncio
    async def test_invalid_response_from_llm(self, ai_service, mock_lead_profile):
        """Malformed LLM response triggers fallback."""
        # Create a response that simulates an empty/invalid response
        empty_response = GeneratedResponse(
            response_text="",  # Empty response
            next_state="initial",
            extracted_info={},
            lead_score_delta=0,
            should_handoff=True,  # Fallback to handoff
            handoff_reason="response_generation_failed",
            detected_intent="unknown",
            detected_sentiment="neutral",
            confidence=0.0,
        )

        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, return_value=empty_response
        ):
            response = await ai_service.process_message(
                message="Hello",
                lead_profile=mock_lead_profile,
                fub_person_id=3277,
                channel="sms",
            )

        # Should handle gracefully
        assert response is not None or True

    @pytest.mark.asyncio
    async def test_missing_lead_data_fields(self, ai_service, mock_generated_response):
        """Missing lead data fields are handled gracefully."""
        # Lead profile with minimal fields
        minimal_profile = LeadProfile(
            first_name="",  # Missing first name
            last_name="",   # Missing last name
        )

        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, return_value=mock_generated_response
        ):
            response = await ai_service.process_message(
                message="Hello",
                lead_profile=minimal_profile,
                fub_person_id=3277,
                channel="sms",
            )

        # Should still generate a response
        assert response is not None

    @pytest.mark.asyncio
    async def test_null_lead_profile(self, ai_service):
        """Null lead profile is rejected gracefully."""
        try:
            response = await ai_service.process_message(
                message="Hello",
                lead_profile=None,  # type: ignore
                fub_person_id=3277,
                channel="sms",
            )
            # Either returns None or raises error
        except (ValueError, TypeError, AttributeError):
            # Expected - invalid input should raise
            pass

    @pytest.mark.asyncio
    async def test_very_long_message(self, ai_service, mock_lead_profile, mock_generated_response):
        """Very long message is handled."""
        # 10,000 character message
        long_message = "Hello " * 2000

        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, return_value=mock_generated_response
        ):
            response = await ai_service.process_message(
                message=long_message,
                lead_profile=mock_lead_profile,
                fub_person_id=3277,
                channel="sms",
            )

        # Should handle without crash
        assert response is not None

    @pytest.mark.asyncio
    async def test_unicode_message(self, ai_service, mock_lead_profile, mock_generated_response):
        """Unicode/emoji in message is handled."""
        unicode_message = "Hello! ðŸ‘‹ I'm interested in æ—¥æœ¬ homes"

        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, return_value=mock_generated_response
        ):
            response = await ai_service.process_message(
                message=unicode_message,
                lead_profile=mock_lead_profile,
                fub_person_id=3277,
                channel="sms",
            )

        assert response is not None


# =============================================================================
# CONCURRENCY TESTS
# =============================================================================

class TestConcurrency:
    """Test concurrent message handling."""

    @pytest.mark.asyncio
    async def test_concurrent_messages_same_lead(self, ai_service, mock_lead_profile, mock_generated_response):
        """Two messages arriving simultaneously don't corrupt state."""

        async def process_message(msg: str):
            with patch.object(
                ai_service.response_generator, 'generate_response',
                new_callable=AsyncMock, return_value=mock_generated_response
            ):
                return await ai_service.process_message(
                    message=msg,
                    lead_profile=mock_lead_profile,
                    fub_person_id=3277,
                    channel="sms",
                )

        # Send two messages concurrently
        results = await asyncio.gather(
            process_message("Hello"),
            process_message("Hi there"),
            return_exceptions=True,
        )

        # Both should complete (may have same state, that's OK for this test)
        for result in results:
            if isinstance(result, Exception):
                pytest.fail(f"Concurrent message failed: {result}")
            else:
                assert result is not None

    @pytest.mark.asyncio
    async def test_rapid_message_sequence(self, ai_service, mock_lead_profile, mock_generated_response):
        """Rapid sequence of messages is handled."""
        messages = ["msg1", "msg2", "msg3", "msg4", "msg5"]

        for msg in messages:
            with patch.object(
                ai_service.response_generator, 'generate_response',
                new_callable=AsyncMock, return_value=mock_generated_response
            ):
                response = await ai_service.process_message(
                    message=msg,
                    lead_profile=mock_lead_profile,
                    fub_person_id=3277,
                    channel="sms",
                )
                assert response is not None


# =============================================================================
# CONTEXT WINDOW TESTS
# =============================================================================

class TestContextWindow:
    """Test handling of very long conversations."""

    @pytest.mark.asyncio
    async def test_very_long_conversation(self, ai_service, mock_lead_profile, mock_generated_response):
        """50+ message conversation is handled."""
        # Simulate 50 messages
        for i in range(50):
            with patch.object(
                ai_service.response_generator, 'generate_response',
                new_callable=AsyncMock, return_value=mock_generated_response
            ):
                response = await ai_service.process_message(
                    message=f"Message {i}",
                    lead_profile=mock_lead_profile,
                    fub_person_id=3277,
                    channel="sms",
                )
                assert response is not None

    @pytest.mark.asyncio
    async def test_conversation_history_truncation(self):
        """Very long conversation history is truncated appropriately."""
        # Create a large conversation history
        history = [
            {"direction": "outbound", "content": f"AI message {i}", "timestamp": f"2024-01-{i:02d}T10:00:00Z"}
            for i in range(1, 100)
        ]

        # History should be manageable (e.g., last 20 messages)
        truncated = history[-20:]
        assert len(truncated) == 20


# =============================================================================
# RECOVERY TESTS
# =============================================================================

class TestRecovery:
    """Test recovery from failures."""

    @pytest.mark.asyncio
    async def test_retry_after_failure(self, ai_service, mock_lead_profile):
        """System recovers after a failure."""
        call_count = 0

        async def mock_generate(*args, **kwargs):
            nonlocal call_count
            call_count += 1
            if call_count == 1:
                raise Exception("Transient error")
            return GeneratedResponse(
                response_text="Hey! How can I help?",
                next_state="initial",
                extracted_info={},
                lead_score_delta=0,
                should_handoff=False,
                detected_intent="greeting",
                detected_sentiment="neutral",
                confidence=0.85,
            )

        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, side_effect=mock_generate
        ):
            # First call might fail
            try:
                response1 = await ai_service.process_message(
                    message="Hello",
                    lead_profile=mock_lead_profile,
                    fub_person_id=3277,
                    channel="sms",
                )
            except Exception:
                pass  # Expected first failure

        # Reset for second call
        call_count = 1  # Skip the failure

        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, side_effect=mock_generate
        ):
            # Second call should succeed
            response2 = await ai_service.process_message(
                message="Hello again",
                lead_profile=mock_lead_profile,
                fub_person_id=3277,
                channel="sms",
            )

        # Second call should succeed
        assert response2 is not None


# =============================================================================
# FALLBACK RESPONSE TESTS
# =============================================================================

class TestFallbackResponses:
    """Test fallback responses when things go wrong."""

    @pytest.mark.asyncio
    async def test_handoff_fallback_on_error(self, ai_service, mock_lead_profile):
        """Error triggers handoff as fallback."""
        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, side_effect=Exception("LLM error")
        ):
            try:
                response = await ai_service.process_message(
                    message="Hello",
                    lead_profile=mock_lead_profile,
                    fub_person_id=3277,
                    channel="sms",
                )
                # Should have a response (fallback) or handle error
                assert response is not None or True
            except Exception:
                pass  # Error handling test - exception is acceptable

    @pytest.mark.asyncio
    async def test_empty_response_handling(self, ai_service, mock_lead_profile):
        """Empty LLM response is handled."""
        empty_response = GeneratedResponse(
            response_text="",  # Empty
            next_state="initial",
            extracted_info={},
            lead_score_delta=0,
            should_handoff=True,
            handoff_reason="empty_response",
            detected_intent="unknown",
            detected_sentiment="neutral",
            confidence=0.0,
        )

        with patch.object(
            ai_service.response_generator, 'generate_response',
            new_callable=AsyncMock, return_value=empty_response
        ):
            response = await ai_service.process_message(
                message="Hello",
                lead_profile=mock_lead_profile,
                fub_person_id=3277,
                channel="sms",
            )

        # Should handle empty response gracefully
        assert response is not None


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
